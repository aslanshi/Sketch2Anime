{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement according to: https://github.com/bobbens/sketch_simplification\n",
    "# Paper: https://arxiv.org/pdf/1703.08966.pdf\n",
    "\n",
    "# pytorch 0.4.1\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.serialization import load_lua\n",
    "from PIL import Image\n",
    "\n",
    "conv_ske_dic = 'E:/Code/Anime Faces/out/'\n",
    "simp_ske_dic = './Data/input_ps/'\n",
    "\n",
    "cache  = load_lua('./Models/simplify _sketch_model.t7', long_size = 8)\n",
    "model  = cache.model\n",
    "immean = cache.mean\n",
    "imstd  = cache.std\n",
    "model.evaluate()\n",
    "use_cuda = torch.cuda.device_count() > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<bound method Container.parameters of nn.Sequential {\n",
       "  [input -> (0) -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> (13) -> (14) -> (15) -> (16) -> (17) -> (18) -> (19) -> (20) -> (21) -> (22) -> (23) -> (24) -> (25) -> (26) -> (27) -> (28) -> (29) -> (30) -> (31) -> (32) -> (33) -> (34) -> (35) -> (36) -> (37) -> (38) -> (39) -> (40) -> (41) -> (42) -> (43) -> (44) -> (45) -> output]\n",
       "  (0): nn.SpatialConvolution(1 -> 48, 5x5, 2, 2, 2, 2)\n",
       "  (1): nn.ReLU\n",
       "  (2): nn.SpatialConvolution(48 -> 128, 3x3, 1, 1, 1, 1)\n",
       "  (3): nn.ReLU\n",
       "  (4): nn.SpatialConvolution(128 -> 128, 3x3, 1, 1, 1, 1)\n",
       "  (5): nn.ReLU\n",
       "  (6): nn.SpatialConvolution(128 -> 128, 3x3, 2, 2, 1, 1)\n",
       "  (7): nn.ReLU\n",
       "  (8): nn.SpatialConvolution(128 -> 256, 3x3, 1, 1, 1, 1)\n",
       "  (9): nn.ReLU\n",
       "  (10): nn.SpatialConvolution(256 -> 256, 3x3, 1, 1, 1, 1)\n",
       "  (11): nn.ReLU\n",
       "  (12): nn.SpatialConvolution(256 -> 256, 3x3, 2, 2, 1, 1)\n",
       "  (13): nn.ReLU\n",
       "  (14): nn.SpatialConvolution(256 -> 512, 3x3, 1, 1, 1, 1)\n",
       "  (15): nn.ReLU\n",
       "  (16): nn.SpatialConvolution(512 -> 1024, 3x3, 1, 1, 1, 1)\n",
       "  (17): nn.ReLU\n",
       "  (18): nn.SpatialConvolution(1024 -> 1024, 3x3, 1, 1, 1, 1)\n",
       "  (19): nn.ReLU\n",
       "  (20): nn.SpatialConvolution(1024 -> 1024, 3x3, 1, 1, 1, 1)\n",
       "  (21): nn.ReLU\n",
       "  (22): nn.SpatialConvolution(1024 -> 1024, 3x3, 1, 1, 1, 1)\n",
       "  (23): nn.ReLU\n",
       "  (24): nn.SpatialConvolution(1024 -> 512, 3x3, 1, 1, 1, 1)\n",
       "  (25): nn.ReLU\n",
       "  (26): nn.SpatialConvolution(512 -> 256, 3x3, 1, 1, 1, 1)\n",
       "  (27): nn.ReLU\n",
       "  (28): nn.SpatialFullConvolution(256 -> 256, 4x4, 2, 2, 1, 1)\n",
       "  (29): nn.ReLU\n",
       "  (30): nn.SpatialConvolution(256 -> 256, 3x3, 1, 1, 1, 1)\n",
       "  (31): nn.ReLU\n",
       "  (32): nn.SpatialConvolution(256 -> 128, 3x3, 1, 1, 1, 1)\n",
       "  (33): nn.ReLU\n",
       "  (34): nn.SpatialFullConvolution(128 -> 128, 4x4, 2, 2, 1, 1)\n",
       "  (35): nn.ReLU\n",
       "  (36): nn.SpatialConvolution(128 -> 128, 3x3, 1, 1, 1, 1)\n",
       "  (37): nn.ReLU\n",
       "  (38): nn.SpatialConvolution(128 -> 48, 3x3, 1, 1, 1, 1)\n",
       "  (39): nn.ReLU\n",
       "  (40): nn.SpatialFullConvolution(48 -> 48, 4x4, 2, 2, 1, 1)\n",
       "  (41): nn.ReLU\n",
       "  (42): nn.SpatialConvolution(48 -> 24, 3x3, 1, 1, 1, 1)\n",
       "  (43): nn.ReLU\n",
       "  (44): nn.SpatialConvolution(24 -> 1, 3x3, 1, 1, 1, 1)\n",
       "  (45): nn.Sigmoid\n",
       "}>"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names = [f for f in os.listdir(conv_ske_dic) if f.endswith('.png')]\n",
    "# name_file = open('name_file.txt', 'a')\n",
    "# for n in names:\n",
    "#     if n == names[-1]:\n",
    "#         name_file.write(n)\n",
    "#     else:\n",
    "#         name_file.write(n + ',')\n",
    "# name_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnimeSketchDataset(Dataset):\n",
    "    \"\"\"Anime Sketches dataset converted from the original pictures\"\"\"\n",
    "    \n",
    "    def __init__(self, img_names, root_dir, transform=None):\n",
    "        \n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img_names (string): a path to a txt file of sketches file names.\n",
    "            root_dir (string): directory with all converted sketches.\n",
    "            transform (callable, optional): optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.names = open(img_names, 'r').read().split(',')\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.names)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        img = os.path.join(self.root_dir, self.names[idx])\n",
    "        data = Image.open(img).convert('L')\n",
    "        \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "            \n",
    "        return {'image': data, 'image_name': self.names[idx]}\n",
    "        \n",
    "class Preprocess():\n",
    "    \"\"\"Preprocess the images as proposed in the paper\"\"\"\n",
    "    \n",
    "    def __init__(self, immean, imstd):\n",
    "        \n",
    "        self.mean = immean\n",
    "        self.std = imstd\n",
    "    \n",
    "    def __call__(self, data):\n",
    "        \n",
    "        w, h = data.size[0], data.size[1]\n",
    "        pw = 8 - (w%8) if w%8 != 0 else 0\n",
    "        ph = 8 - (h%8) if h%8 != 0 else 0\n",
    "        \n",
    "        data = (transforms.ToTensor()(data) - immean) / imstd\n",
    "        \n",
    "        if pw!=0 or ph!=0:\n",
    "            data = torch.nn.ReplicationPad2d((0, pw, 0, ph))(data).data\n",
    "            \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = AnimeSketchDataset('name_file.txt', conv_ske_dic, Preprocess(immean, imstd))\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'cuda'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-6ac814a882c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'image'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'image_name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'cuda'"
     ]
    }
   ],
   "source": [
    "for inputs in dataloader:\n",
    "    data, img = inputs['image'], inputs['image_name']\n",
    "    if use_cuda:\n",
    "        pred = model.cuda().forward(data.cuda()).float()\n",
    "    else:\n",
    "        pred = model.toforward(data)\n",
    "    for i in range(data.shape[0]):\n",
    "        save_image(pred[i], simp_ske_dic + img[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.7.0 64-bit ('t7env': conda)",
   "display_name": "Python 3.7.0 64-bit ('t7env': conda)",
   "metadata": {
    "interpreter": {
     "hash": "e8c407d403299b39b5c5c6a47d30761a0ce719b929bac15e49948b8ab5d7efe6"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}